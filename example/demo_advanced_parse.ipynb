{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize OpenAI API client with API key from environment variables\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "anthropic_api_key = os.getenv('ANTHROPIC_API_KEY')\n",
    "llama_cloud_api_key = os.getenv('LLAMA_CLOUD_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.core import Settings\n",
    "\n",
    "embed_model = OpenAIEmbedding(model=\"text-embedding-3-small\")\n",
    "llm = OpenAI(model=\"gpt-4o\")\n",
    "\n",
    "Settings.llm = llm\n",
    "Settings.embed_model = embed_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Using MarkdownElementNodeParser for parsing the LlamaParse output Markdown results and building recursive retriever query engine for generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started parsing the file under job_id 7d0ca18e-660a-407c-868d-3417f465b74b\n",
      "......."
     ]
    }
   ],
   "source": [
    "from llama_parse import LlamaParse\n",
    "\n",
    "# Define the path to the text file within the 'docs' directory\n",
    "text_file_path = './docs/article_2024-08-16_2024-08-29.txt'\n",
    "\n",
    "\n",
    "# Parse the text data as markdown\n",
    "documents = LlamaParse(result_type=\"markdown\").load_data(\"./docs/article_2024-08-16_2024-08-29.txt\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "from llama_index.core.schema import TextNode\n",
    "from llama_index.core import VectorStoreIndex\n",
    "\n",
    "\n",
    "def get_page_nodes(docs, separator=\"\\n========================================\\n\"):\n",
    "    \"\"\"Split each document into page node, by separator.\"\"\"\n",
    "    nodes = []\n",
    "    for doc in docs:\n",
    "        doc_chunks = doc.text.split(separator)\n",
    "        for doc_chunk in doc_chunks:\n",
    "            node = TextNode(\n",
    "                text=doc_chunk,\n",
    "                metadata=deepcopy(doc.metadata),\n",
    "            )\n",
    "            nodes.append(node)\n",
    "\n",
    "    return nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_nodes = get_page_nodes(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.node_parser import MarkdownElementNodeParser\n",
    "\n",
    "node_parser = MarkdownElementNodeParser(\n",
    "    llm=OpenAI(model=\"gpt-4o\"), num_workers=8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = node_parser.get_nodes_from_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_nodes, objects = node_parser.get_nodes_and_objects(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This table shows the emergency disaster response scores of four countries: the Philippines, Cambodia, Vietnam, and Thailand.,\\nwith the following columns:\\n- ประเทศ: None\\n- คะแนนการรับมือเหตุภัยพิบัติฉุกเฉิน: None\\n'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "objects[0].get_content()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dump both indexed tables and page text into the vector index\n",
    "recursive_index = VectorStoreIndex(nodes=base_nodes + objects + page_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(page_nodes[31].get_content())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.postprocessor.flag_embedding_reranker import FlagEmbeddingReranker\n",
    "\n",
    "reranker = FlagEmbeddingReranker(\n",
    "    top_n=5,\n",
    "    model=\"BAAI/bge-reranker-large\",\n",
    ")\n",
    "\n",
    "recursive_query_engine = recursive_index.as_query_engine(\n",
    "    similarity_top_k=5, node_postprocessors=[reranker], verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1285\n"
     ]
    }
   ],
   "source": [
    "print(len(nodes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Setup Baseline** ####\n",
    "For comparison, we setup a naive RAG pipeline with default parsing and standard chunking, indexing, retrieval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SimpleDirectoryReader\n",
    "\n",
    "reader = SimpleDirectoryReader(input_files=[\"./docs/article_2024-08-16_2024-08-29.txt\"])\n",
    "base_docs = reader.load_data()\n",
    "raw_index = VectorStoreIndex.from_documents(base_docs)\n",
    "raw_query_engine = raw_index.as_query_engine(\n",
    "    similarity_top_k=5, node_postprocessors=[reranker]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "***********Basic Query Engine***********\n",
      "The news covers a span of 14 days.\n",
      "\n",
      "***********New LlamaParse+ Recursive Retriever Query Engine***********\n",
      "The news covers events from August 26, 2024.\n",
      "\n",
      "***********Basic Query Engine***********\n",
      "There are no news articles related to politics from the 25th of August in the provided information. The articles listed are from dates ranging from the 16th to the 23rd of August.\n",
      "\u001b[1;3;38;2;11;159;203mRetrieval entering c8452cce-0477-45a4-a946-5c3c0491ff02: TextNode\n",
      "\u001b[0m\u001b[1;3;38;2;237;90;200mRetrieving from object TextNode with query can you highlight news related to poltics from 25th of Auguest? list them out and explain\n",
      "\u001b[0m\u001b[1;3;38;2;11;159;203mRetrieval entering a3aee2f5-3123-4710-8a06-79a949972f04: TextNode\n",
      "\u001b[0m\u001b[1;3;38;2;237;90;200mRetrieving from object TextNode with query can you highlight news related to poltics from 25th of Auguest? list them out and explain\n",
      "\u001b[0m\u001b[1;3;38;2;11;159;203mRetrieval entering 6b7f6476-13ea-4da5-a62a-aa6feed74d40: TextNode\n",
      "\u001b[0m\u001b[1;3;38;2;237;90;200mRetrieving from object TextNode with query can you highlight news related to poltics from 25th of Auguest? list them out and explain\n",
      "\u001b[0m\u001b[1;3;38;2;11;159;203mRetrieval entering 17369a15-9ecd-47fe-810e-86057d3cf3cb: TextNode\n",
      "\u001b[0m\u001b[1;3;38;2;237;90;200mRetrieving from object TextNode with query can you highlight news related to poltics from 25th of Auguest? list them out and explain\n",
      "\u001b[0m\u001b[1;3;38;2;11;159;203mRetrieval entering e9877dfe-3565-4121-a57a-f3ee70f5b360: TextNode\n",
      "\u001b[0m\u001b[1;3;38;2;237;90;200mRetrieving from object TextNode with query can you highlight news related to poltics from 25th of Auguest? list them out and explain\n",
      "\u001b[0m\n",
      "***********New LlamaParse+ Recursive Retriever Query Engine***********\n",
      "There are no news articles related to politics from the 25th of August in the provided information. The articles listed are from the 23rd and 28th of August.\n",
      "\n",
      "***********Basic Query Engine***********\n",
      "The news categories covered include politics, national politics, and economics.\n",
      "\u001b[1;3;38;2;11;159;203mRetrieval entering a3aee2f5-3123-4710-8a06-79a949972f04: TextNode\n",
      "\u001b[0m\u001b[1;3;38;2;237;90;200mRetrieving from object TextNode with query what are the category of news do you cover?\n",
      "\u001b[0m\n",
      "***********New LlamaParse+ Recursive Retriever Query Engine***********\n",
      "The categories of news covered include politics, national politics, business, economy, IT, and technology.\n",
      "Exiting the query loop.\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    # Prompt the user for a query\n",
    "    query = input(\"Enter your query (or type 'exit' to quit): \")\n",
    "    \n",
    "    # Exit the loop if the user types 'exit'\n",
    "    if query.lower() == 'exit':\n",
    "        print(\"Exiting the query loop.\")\n",
    "        break\n",
    "    \n",
    "    # Execute the query using the raw query engine\n",
    "    response_1 = raw_query_engine.query(query)\n",
    "    print(\"\\n***********Basic Query Engine***********\")\n",
    "    print(response_1)\n",
    "    \n",
    "    # Execute the query using the recursive query engine\n",
    "    response_2 = recursive_query_engine.query(query)\n",
    "    print(\"\\n***********New LlamaParse+ Recursive Retriever Query Engine***********\")\n",
    "    print(response_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
